{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Outputs a **.csv** file with metrics on repositories from the following organizations:\n",
    "- googlesamples\n",
    "- aws-samples\n",
    "- Azure-Samples\n",
    "- spring-guides \n",
    "- googlearchive\n",
    "- spring-cloud-samples\n",
    "-spring-io\n",
    "#### The metrics include:\n",
    "- full_name\n",
    "- name\n",
    "- owner\n",
    "- html_url\n",
    "- description\n",
    "- created_at\n",
    "- updated_at\n",
    "- pushed_at\n",
    "- size\n",
    "- language\n",
    "- forks_count\n",
    "- stargazers_count\n",
    "- subscribers_count\n",
    "- watchers_count\n",
    "- network_count\n",
    "- archived\n",
    "- total_lines\n",
    "- langs_percentage\n",
    "<div class=\"alert alert-box alert-info\">\n",
    "    <b>Note:</b> You can change the organizations by modifying the list of organizations in the code cell below.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "ORGANIZATIONS = [\n",
    "    # \"aws-samples\", # 6.3k\n",
    "    # \"Azure-Samples\", # 2.6k\n",
    "     \"googlesamples\", # 71\n",
    "    # \"spring-guides\", # 74\n",
    "    # \"googlearchive\", # 973\n",
    "    # \"spring-cloud-samples\", # 29\n",
    "]\n",
    "\n",
    "EXCLUDED_REPOS = [\n",
    "    \"googlearchive/digits-migration-helper-android\",\n",
    "    \"googlearchive/play-apk-expansion\",\n",
    "    \"googlearchive/tiger\",\n",
    "    \"googlearchive/two-token-sw\",\n",
    "    \"googlearchive/Abelana-Android\",\n",
    "    \"googlearchive/solutions-mobile-backend-starter-java\"\n",
    "]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "%pip install PyGithub python-dotenv pandas tqdm cachetools matplotlib seaborn"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from github import Github\n",
    "import os\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from os import getenv\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from cachetools import cached, TTLCache"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "load_dotenv()\n",
    "g = Github(getenv('GITHUB_TOKEN'), per_page=100)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "cache = TTLCache(maxsize=1024, ttl=300)\n",
    "\n",
    "def fetch_organization_repositories(organization_name, language=None):\n",
    "    repo_data = []\n",
    "    organization = g.get_organization(organization_name)\n",
    "    repos = organization.get_repos(\"all\")\n",
    "    total_repos = repos.totalCount\n",
    "\n",
    "    @cached(cache)\n",
    "    def process_repo(repo):\n",
    "        if repo.full_name in EXCLUDED_REPOS:\n",
    "            return None\n",
    "        if language and repo.language != language:\n",
    "            return None\n",
    "        if organization_name == \"googlearchive\" and not is_valid_googlearchive_repo(repo):\n",
    "            return None\n",
    "        elif organization_name == \"SAP-samples\" and not is_valid_sap_sample_repo(repo):\n",
    "            return None\n",
    "        \n",
    "        repo_languages = repo.get_languages()\n",
    "        total_lines = sum(repo_languages.values())\n",
    "        language_percentages = {lang: f'{(lines/total_lines):.2%}' for lang, lines in repo_languages.items()}\n",
    "        \n",
    "        all_issues = list(repo.get_issues(state=\"all\"))\n",
    "        open_issues_count = sum(1 for issue in all_issues if issue.state == \"open\")\n",
    "        closed_issues_count = len(all_issues) - open_issues_count\n",
    "\n",
    "        all_pulls = list(repo.get_pulls(state='all'))\n",
    "        open_pulls_count = sum(1 for pull in all_pulls if pull.state == \"open\")\n",
    "        closed_pulls_count = len(all_pulls) - open_pulls_count\n",
    "        merged_pulls_count = sum(1 for pull in all_pulls if pull.merged)\n",
    "\n",
    "        commits = list(repo.get_commits())\n",
    "        commits_count = len(commits)\n",
    "        first_commit_date = commits[-1].commit.author.date if commits else None\n",
    "        last_commit_date = commits[0].commit.author.date if commits else None\n",
    "        \n",
    "        return {\n",
    "        \"full_name\": repo.full_name,\n",
    "        \"name\": repo.name,\n",
    "        \"owner\": repo.owner.login,\n",
    "        \"html_url\": repo.html_url,\n",
    "        \"description\": repo.description, \n",
    "        \"created_at\": repo.created_at,\n",
    "        \"updated_at\": repo.updated_at, \n",
    "        \"pushed_at\": repo.pushed_at,\n",
    "        \"size\": repo.size, \n",
    "        \"language\": repo.language, \n",
    "        \"forks_count\": repo.forks_count,\n",
    "        \"stargazers_count\": repo.stargazers_count, \n",
    "        \"subscribers_count\": repo.subscribers_count,\n",
    "        \"watchers_count\": repo.watchers_count,\n",
    "        \"network_count\": repo.network_count,\n",
    "        \"archived\": repo.archived,\n",
    "        \"total_lines\": total_lines,\n",
    "        \"langs_percentage\": language_percentages,\n",
    "        \"issues_count\": len(all_issues),\n",
    "        \"closed_issues_count\": closed_issues_count,\n",
    "        \"open_issues_count\": open_issues_count,\n",
    "        \"total_issues_count\": closed_issues_count + open_issues_count,\n",
    "        \"closed_pulls_count\": closed_pulls_count,\n",
    "        \"open_pulls_count\": open_pulls_count,\n",
    "        \"total_pulls_count\": closed_pulls_count + open_pulls_count,\n",
    "        \"merged_pulls_count\": merged_pulls_count,\n",
    "        \"commits_count\": commits_count,\n",
    "        \"first_commit_date\": first_commit_date,\n",
    "        \"last_commit_date\": last_commit_date,\n",
    "        \"branches_count\": int(repo.get_branches().totalCount),\n",
    "        \"topics\": str(tuple(repo.topics)),\n",
    "        \"contributors_count\": int(repo.get_contributors().totalCount)\n",
    "        }\n",
    "\n",
    "\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        futures = [executor.submit(process_repo, repo) for repo in repos]\n",
    "        for future in tqdm(as_completed(futures), total=total_repos, desc=organization_name, unit=\" repos\", ncols=100, bar_format='{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_fmt}{postfix}] {percentage:3.0f}%'):\n",
    "            try:\n",
    "                result = future.result()\n",
    "                repo_data.append(result)\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"Error fetching data for repo, error: {e}\")\n",
    "\n",
    "    return pd.DataFrame(repo_data)\n",
    "\n",
    "def is_valid_googlearchive_repo(repo):\n",
    "    if not repo.description:\n",
    "        return False\n",
    "    keywords = [\"example\", \"sample\", \"migrated\"]\n",
    "    return any(keyword in repo.description.lower() for keyword in keywords) or any(keyword in repo.full_name.lower() for keyword in keywords)\n",
    "\n",
    "def is_valid_sap_sample_repo(repo):\n",
    "    if not repo.description:\n",
    "        return False\n",
    "    keywords = [\"cloud\"]\n",
    "    return any(keyword in repo.description.lower() for keyword in keywords) or any(keyword in repo.full_name.lower() for keyword in keywords)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='alert alert-box alert-info'>\n",
    "    Below is the code that generates the <b>.csv</b> metrics file.\n",
    "    You can change the language by modifying the <i style='color: red'>language</i> variable in the code cell below.\n",
    "</div>\n",
    "<div class='alert alert-box alert-warning'>\n",
    "    <b>Note:</b> The <i style='color: blue'>language</i> variable is case sensitive and can be <i style='color: blue'>None</i>, if you want to get all the repositories.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "def generate_metrics_csv(name):\n",
    "    \n",
    "    if not os.path.exists('codesamples'): \n",
    "        os.makedirs(\"codesamples\")\n",
    "    \n",
    "    all_repos_data = []\n",
    "    \n",
    "    def fetch_data_for_organization(organization):\n",
    "        print(f'Retrieving repos from {organization}...')\n",
    "        organization_repos_data = fetch_organization_repositories(organization, language=None)\n",
    "        if not organization_repos_data.empty:\n",
    "            return organization_repos_data\n",
    "        else:\n",
    "            return pd.DataFrame()\n",
    "\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        futures = [executor.submit(fetch_data_for_organization, org) for org in ORGANIZATIONS]\n",
    "        for future in tqdm(as_completed(futures), desc=\"Processing organizations\", unit=\" orgs\", total=len(ORGANIZATIONS), ncols=100, bar_format='{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_fmt}{postfix}] {percentage:3.0f}%'):\n",
    "            org_data = future.result()\n",
    "            if not org_data.empty:\n",
    "                all_repos_data.append(org_data)\n",
    "\n",
    "    all_repos_data_df = pd.concat(all_repos_data, ignore_index=True) if all_repos_data else pd.DataFrame()\n",
    "    timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "    file_path = f\"codesamples/{name}_{timestamp}.csv\"\n",
    "    all_repos_data_df.to_csv(file_path, index=False)\n",
    "\n",
    "    return all_repos_data_df"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "dataframe = generate_metrics_csv('spring_cloud')\n",
    "dataframe"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
